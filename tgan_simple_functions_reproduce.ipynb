{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4929b505-95e7-4a9d-b20e-bb9f8de57bd1",
   "metadata": {},
   "source": [
    "### TimeGAN example using basis functions\n",
    "\n",
    "The purpose of this notebook is to demonstrate reproducibility issues of TimeGAN model\n",
    "\n",
    "Please check that all dependencies from `requirements.txt` are installed.\n",
    "GPU usage is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6ef9e-5932-4a6e-8e62-e633a7cf7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d95e1d-c40d-45d5-8422-36dea7a1b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from ydata_synthetic.synthesizers.timeseries import TimeGAN\n",
    "from ydata_synthetic.synthesizers import ModelParameters\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sequences import sliding_window, split_sequence2Xy\n",
    "from plotting import plot_sample_sequences, plot_pca_vs_tsne, plot_rnn_forecast\n",
    "from forecast import get_rnn_forecaster\n",
    "from metrics import calculate_metrics\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef306370-a1d0-45d0-aa47-ab931f2b5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = 'models'\n",
    "MODEL_NAME = 'tgan_simple_functions_1500_32_good.pkl'\n",
    "\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, MODEL_NAME)\n",
    "TRAINING_STEPS = 1500\n",
    "SEQUENCE_LENGTH = 32\n",
    "\n",
    "\n",
    "RNN_UNITS = 32\n",
    "RNN_EPOCHS = 100\n",
    "RNN_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a83bc-359e-4761-aca6-a29589528959",
   "metadata": {},
   "source": [
    "## Step 1: Load data\n",
    "\n",
    "In our case, we generate a couple of simple 1-dimentional functions samples:\n",
    "\n",
    "* Constant\n",
    "* Sin\n",
    "* Cos\n",
    "\n",
    "The idea is that any complex model should be able to capture such simple patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56f75d-d476-4cf9-856d-7dd562c9ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "linear = np.linspace(0, 1000, num=n_samples)\n",
    "cos = np.cos(linear)\n",
    "sin = np.sin(linear)\n",
    "constant = np.ones((n_samples, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a136177-cbce-4819-9538-528e0ddb6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.vstack((constant, sin, cos)).T, columns=['constant', 'sin(x)', 'cos(x)'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4786de8c-7daf-40d2-828f-c13801108f32",
   "metadata": {},
   "source": [
    "## Step 2: Data preprocessing\n",
    "\n",
    "### a.Train-test split\n",
    "\n",
    "Please note that train-test split is, in general, not required, as this model is self-supervised.\n",
    "\n",
    "However, if you're going to train classifier based on augmented data, you should split train and test.\n",
    "\n",
    "This will ensure you do not expose test data to the data augmentation process, which otherwise would lead to overoptimistic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52627cf7-5f37-4bc3-9737-0d137eba321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte = train_test_split(X, test_size=.33, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1427b62-e412-49e7-8b99-57b5c7c4cca1",
   "metadata": {},
   "source": [
    "### b. Perform scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eda309-2ab7-43b8-9280-e0a754a5d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "Xtr_scaled = scaler.fit_transform(Xtr)\n",
    "Xte_scaled = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a566509-20b2-4b69-b9da-c963fb1cb85d",
   "metadata": {},
   "source": [
    "### c. Create slices of time-series to train model\n",
    "\n",
    "Notice that we use this function later on, when we specify sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7fa52c-4b05-4b04-b07f-fcd5fc001022",
   "metadata": {},
   "source": [
    "## Step 3: Define parameters and train a model\n",
    "\n",
    "Since documentation is scarse, we explain some of the parameters below:\n",
    "\n",
    "* `n_seq`: amount of features (columns) in your dataset\n",
    "* `seq_len`: sliding window size (basically amount of consecutive samples considered at once)\n",
    "\n",
    "* `training_steps`: amount of epochs to train models.\n",
    "\n",
    "Observation on `train_steps`: you need at least 1000 training steps to get reasonable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c23579-512f-4989-a51e-d923ceb23b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = ModelParameters(layers_dim=16, noise_dim=32)\n",
    "\n",
    "hidden_dim = 16\n",
    "n_features = len(X.columns)\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d7835-d462-420e-b011-5819765e9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = sliding_window(Xtr_scaled, SEQUENCE_LENGTH)\n",
    "train_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7a80a-1432-4a64-ac42-b73bb15649ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = sliding_window(Xte_scaled, SEQUENCE_LENGTH)\n",
    "test_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba4a61-85e3-45da-ab7d-5a89b36b195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e23d26-fde2-4c97-b184-9ba261c0896c",
   "metadata": {},
   "source": [
    "Let's plot some examples to see how it looks. We expect samples from the trained model to look similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d6488-ae36-4f9d-98b2-a15ac0220f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample_sequences(train_sequences, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522c0e7-36ed-47c1-b294-6eb8939e84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GANS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b0ab6-ce15-4780-851f-440c64b7d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_GANS):\n",
    "    tf.random.set_seed(42)\n",
    "    gan = TimeGAN(model_params, hidden_dim, SEQUENCE_LENGTH, n_features, gamma) \n",
    "    gan.train(train_sequences, TRAINING_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e48c5-9305-47cd-9981-66760c00aecc",
   "metadata": {},
   "source": [
    "## Step 4: Generate samples\n",
    "\n",
    "Notice, that at least one full batch is generated, regardless what the input to `model.sample()` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce50d49-2fad-46c1-a8da-7ec071ef7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = gan.sample(len(train_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfb450-955b-46f5-8dd4-21339360d586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample_sequences(samples, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fd0f4-d93d-42cc-a42f-93e400aa4ae8",
   "metadata": {},
   "source": [
    "## Step 5: Compare distribution statistics of real and synthetic data\n",
    "\n",
    "# a: by looking at 2D projections comparison\n",
    "\n",
    "Here we:\n",
    "1. Sample the real and synthetic data\n",
    "2. Train pca on real data, transform both real and synthetic\n",
    "3. Build t-SNE projection using the same logic\n",
    "\n",
    "The idea here is that, if data distribution is preserved, then by using a basis of real data principal components, synthetic data should arrange itself in the similar, compact representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05e3dd-180a-4e22-b404-a1f8655f05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_vs_tsne(train_sequences, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3739e98b-19ec-470a-8d81-6f3e863838c5",
   "metadata": {},
   "source": [
    "### b. By comparing identical models trained on real vs synth data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff953c51-16e5-40c0-ae64-95d39f718fa3",
   "metadata": {},
   "source": [
    "Now, assuming we have already generated sequences of size `sequence_len`, we can split each sequence into `train_sequence = sequence[:sequence_len-1]` and target `train_target = sequence[sequence_len]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde4b2e-36a9-44ec-a264-2024948f2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_w_synth = np.concatenate([train_sequences, samples])\n",
    "np.random.seed(42)\n",
    "real_w_synth = np.random.permutation(real_w_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef5405-8790-4548-81d9-7c034ab1d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_train, y_real_train = split_sequence2Xy(train_sequences)\n",
    "\n",
    "# we will use the same test sequences for synth-based model too\n",
    "X_real_test, y_real_test = split_sequence2Xy(test_sequences)\n",
    "\n",
    "X_synth_train, y_synth_train = split_sequence2Xy(samples)\n",
    "\n",
    "X_cmb_train, y_cmb_train = split_sequence2Xy(real_w_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416adfe8-259a-437f-a64d-9ed21dca9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Synthetic X train: {X_synth_train.shape}, y train: {y_synth_train.shape}')\n",
    "print(f'Real X train: {X_real_train.shape}, y train: {y_real_train.shape}')\n",
    "print(f'Combined Real and synth X train: {X_cmb_train.shape}, y train: {y_cmb_train.shape}')\n",
    "\n",
    "print(f'Real X test: {X_real_test.shape}, y test: {y_real_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee4721-9334-4652-8580-8985c2f17cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161a783-101e-4ec6-8b71-795e477a6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_real = get_rnn_forecaster(RNN_UNITS, n_features, name='Real_RNN', input_shape=X_real_train.shape)\n",
    "ts_synth = get_rnn_forecaster(RNN_UNITS, n_features, name='Synth_RNN', input_shape=X_real_train.shape)\n",
    "ts_cmb = get_rnn_forecaster(RNN_UNITS, n_features, name='Real_Synth_RNN', input_shape=X_real_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5e54b-14ca-4c46-91fe-cb3bcebb81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_real.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a4015-eaa6-41fa-b540-1054d9d346e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = ts_real.fit(x=X_real_train,\n",
    "                          y=y_real_train,\n",
    "                          validation_data=(X_real_test, y_real_test),\n",
    "                          epochs=RNN_EPOCHS,\n",
    "                          batch_size=RNN_BATCH_SIZE,\n",
    "                          callbacks=[early_stopping],\n",
    "                          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6939d-bad4-4e06-8f3a-330a5bba05e3",
   "metadata": {},
   "source": [
    "### Tip for Synthetic-based RNN forecast\n",
    "\n",
    "Be careful with early stopping, it can happen preliminary for synthetic data, which is not the case for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400a88a-42a8-426d-9166-8502f82bf3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with the synthetic data\n",
    "\n",
    "synth_train = ts_synth.fit(x=X_synth_train,\n",
    "                          y=y_synth_train,\n",
    "                          validation_data=(X_real_test, y_real_test),\n",
    "                          epochs=RNN_EPOCHS,\n",
    "                          batch_size=RNN_BATCH_SIZE,\n",
    "                          callbacks=[early_stopping],\n",
    "                          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56f88d-5e6a-482b-bbbd-936b2db05a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with the combined real and synthetic data\n",
    "cmb_train = ts_cmb.fit(x=X_cmb_train,\n",
    "                          y=y_cmb_train,\n",
    "                          validation_data=(X_real_test, y_real_test),\n",
    "                          epochs=RNN_EPOCHS,\n",
    "                          batch_size=RNN_BATCH_SIZE,\n",
    "                          callbacks=[early_stopping],\n",
    "                          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa4d88-36de-484b-8a23-71680f7be68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the metrics here as a pandas dataframe\n",
    "real_predictions = ts_real.predict(X_real_test)\n",
    "synth_predictions = ts_synth.predict(X_real_test)\n",
    "cmb_predictions = ts_cmb.predict(X_real_test)\n",
    "\n",
    "real_pred_df = pd.DataFrame(real_predictions, columns=X.columns)\n",
    "synth_pred_df = pd.DataFrame(synth_predictions, columns=X.columns)\n",
    "cmb_pred_df = pd.DataFrame(cmb_predictions, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75339e4-1022-4a33-a248-1f83b7c134c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(y_real_test, real=real_predictions, synth=synth_predictions, combined=cmb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8563bbb-e5dc-4736-bc66-6b829ee405be",
   "metadata": {},
   "source": [
    "Now let's look at visual representation of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0611c-b486-4d83-a90a-5dd721e7e9d5",
   "metadata": {},
   "source": [
    "### Test predictions for RNN based on real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b81c1-3759-48e3-9eb0-ed0e98939db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce0b22-1a2e-49ed-b5fc-18bef66ff2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rnn_forecast(real_pred_df.iloc[:first_n_samples], title='RNN forecast trained on real data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705e503-3759-4393-a76c-c063cece5fa4",
   "metadata": {},
   "source": [
    "### Test predictions for RNN based only on synth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e03a4-6c12-4999-9995-62ee86fbcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rnn_forecast(synth_pred_df.iloc[:first_n_samples], title='RNN forecast trained on synthetic data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46affeee-b4c7-4c30-acba-db3590a97893",
   "metadata": {},
   "source": [
    "### Test predictions of RNN trained on both real and synth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71600374-4fa5-48cf-84d7-974b37cade49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rnn_forecast(cmb_pred_df.iloc[:first_n_samples], title='RNN forecast trained on combined data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
